{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Algorithms in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, data we store or retreive in an application can have little or no order. We may have to rearrange the data to correctly process it or efficiently use it. Sorting is one of the most thoroughly studied algorithms in computer science. There are dozens of different sorting implementations and applications that you can use to make your code omore efficient and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will take a look at popular sorting algorithms, understand how they work and code them in Python, then I will also compare how quickly they sort items in a list. In this project, algorithms would be sorting lists of numbers in ascending order for simplicity, but it should be quite straightforward to modify them to descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Significance of Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For a practical point of view, you’ll measure the runtime of the implementations using the timeit module.\n",
    "2. For a more theoretical perspective, you’ll measure the runtime complexity of the algorithms using Big O notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Your Code's Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing two sorting algorithms in Python, it’s always informative to look at how long each one takes to run. The specific time each algorithm takes will be partly determined by your hardware, but you can still use the proportional time between executions to help you decide which implementation is more time efficient. Here's a function to time your algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from timeit import repeat\n",
    "\n",
    "def run_sorting_algorithm(algorithm, array):\n",
    "    # Set up the context and prepare the call to the specified\n",
    "    # algorithm using the supplied array. Only import the\n",
    "    # algorithm function if it's not the built-in `sorted()`.\n",
    "    setup_code = f\"from __main__ import {algorithm}\" \\\n",
    "        if algorithm != \"sorted\" else \"\"\n",
    "\n",
    "    stmt = f\"{algorithm}({array})\"\n",
    "\n",
    "    # Execute the code ten different times and return the time\n",
    "    # in seconds that each execution took\n",
    "    times = repeat(setup=setup_code, stmt=stmt, repeat=3, number=10)\n",
    "\n",
    "    # Finally, display the name of the algorithm and the\n",
    "    # minimum time it took to run\n",
    "    print(f\"Algorithm: {algorithm}. Minimum execution time: {min(times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to use run_sorting_algorithm() to determine the time it takes to sort an array of ten thousand integer values using sorted():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: sorted. Minimum execution time: 0.01765330000000631\n"
     ]
    }
   ],
   "source": [
    "ARRAY_LENGTH = 10000\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array you just created\n",
    "    run_sorting_algorithm(algorithm=\"sorted\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Efficiency With Big O Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big O is often used to compare different implementations and decide which one is the most efficient, skipping unnecessary details and focusing on what’s most important in the runtime of an algorithm.Big O provides a platform to express runtime complexity in hardware-agnostic terms. With Big O, you express complexity in terms of how quickly your algorithm’s runtime grows relative to the size of the input, especially as the input grows arbitrarily large.\n",
    "\n",
    "Assuming that n is the size of the input to an algorithm, the Big O notation represents the relationship between n and the number of steps the algorithm takes to find a solution. Big O uses a capital letter “O” followed by this relationship inside parentheses. For example, O(n) represents algorithms that execute a number of steps proportional to the size of their input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> 1. Bubble Sort  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple sorting algorithm iterates over a list, comparing elements in pairs and swapping them until the larger elements \"bubble up\" to the end of the list, and the smaller elements stay at the \"bottom\". Bubble sort consists of making multiple passes through a list, comparing elements one by one, and swapping adjacent items that are out of order.\n",
    "\n",
    "Here’s an implementation of a bubble sort algorithm in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(array):\n",
    "    n = len(array)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Create a flag that will allow the function to\n",
    "        # terminate early if there's nothing left to sort\n",
    "        already_sorted = True\n",
    "\n",
    "        # Start looking at each item of the list one by one,\n",
    "        # comparing it with its adjacent value. With each\n",
    "        # iteration, the portion of the array that you look at\n",
    "        # shrinks because the remaining items have already been\n",
    "        # sorted.\n",
    "        for j in range(n - i - 1):\n",
    "            if array[j] > array[j + 1]:\n",
    "                # If the item you're looking at is greater than its\n",
    "                # adjacent value, then swap them\n",
    "                array[j], array[j + 1] = array[j + 1], array[j]\n",
    "\n",
    "                # Since you had to swap two elements,\n",
    "                # set the `already_sorted` flag to `False` so the\n",
    "                # algorithm doesn't finish prematurely\n",
    "                already_sorted = False\n",
    "\n",
    "        # If there were no swaps during the last iteration,\n",
    "        # the array is already sorted, and you can terminate\n",
    "        if already_sorted:\n",
    "            break\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bubble Sort's Big O Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of bubble sort consists of two nested for loops in which the algorithm performs n - 1 comparisons, then n - 2 comparisons, and so on until the final comparison is done. This comes at a total of (n - 1) + (n - 2) + (n - 3) + … + 2 + 1 = n(n-1)/2 comparisons, which can also be written as ½n2 - ½n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can simplify the notation by dropping the constants and the n term, leaving bubble sort with an average- and worst-case complexity of O($n^{2}$).)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Bubble Sort Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: bubble_sort. Minimum execution time: 108.37378530000024\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array you just created\n",
    "    run_sorting_algorithm(algorithm=\"bubble_sort\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 108 seconds to sort the array with ten thousand elements. This represents the fastest execution out of the ten repetitions that run_sorting_algorithm() runs. Executing this script multiple times will produce similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Bubble Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of the bubble sort algorithm is its simplicity. It is straightforward to both implement and understand. This is probably the main reason why most computer science courses introduce the topic of sorting using bubble sort.\n",
    "\n",
    "As you saw before, the disadvantage of bubble sort is that it is slow, with a runtime complexity of O($n^{2}$). Unfortunately, this rules it out as a practical candidate for sorting large arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> 2. Insertion Sort  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm segments the list into sorted and unsorted parts. It iterates over the unsorted segment, and inserts the element being viewed into the correct position of the sorted list. An excellent analogy to explain insertion sort is the way you would sort a deck of cards. Imagine that you’re holding a group of cards in your hands, and you want to arrange them in order. You’d start by comparing a single card step by step with the rest of the cards until you find its correct position. At that point, you’d insert the card in the correct location and start over with a new card, repeating until all the cards in your hand were sorted. \n",
    "\n",
    "Here's an implementation of insertion sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(array):\n",
    "    # Loop from the second element of the array until\n",
    "    # the last element\n",
    "    for i in range(1, len(array)):\n",
    "        # This is the element we want to position in its\n",
    "        # correct place\n",
    "        key_item = array[i]\n",
    "\n",
    "        # Initialize the variable that will be used to\n",
    "        # find the correct position of the element referenced\n",
    "        # by `key_item`\n",
    "        j = i - 1\n",
    "\n",
    "        # Run through the list of items (the left\n",
    "        # portion of the array) and find the correct position\n",
    "        # of the element referenced by `key_item`. Do this only\n",
    "        # if `key_item` is smaller than its adjacent values.\n",
    "        while j >= 0 and array[j] > key_item:\n",
    "            # Shift the value one position to the left\n",
    "            # and reposition j to point to the next element\n",
    "            # (from right to left)\n",
    "            array[j + 1] = array[j]\n",
    "            j -= 1\n",
    "\n",
    "        # When you finish shifting the elements, you can position\n",
    "        # `key_item` in its correct location\n",
    "        array[j + 1] = key_item\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bubble Sort's Big O Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the bubble sort implementation, the insertion sort algorithm has a couple of nested loops that go over the list. The inner loop is pretty efficient because it only goes through the list until it finds the correct position of an element. That said, the algorithm still has an O($n^{2}$) runtime complexity on the average case.\n",
    "\n",
    "The worst case happens when the supplied array is sorted in reverse order. In this case, the inner loop has to execute every comparison to put every element in its correct position. This still gives you an O($n^{2}$) runtime complexity.\n",
    "\n",
    "Although bubble sort and insertion sort have the same Big O runtime complexity, in practice, insertion sort is considerably more efficient than bubble sort. If you look at the implementation of both algorithms, then you can see how insertion sort has to make fewer comparisons to sort the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Insertion Sort Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: insertion_sort. Minimum execution time: 50.2901797999948\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array we just created\n",
    "    run_sorting_algorithm(algorithm=\"insertion_sort\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Insertion Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like bubble sort, the insertion sort algorithm is very uncomplicated to implement. Even though insertion sort is an O(n2) algorithm, it’s also much more efficient in practice than other quadratic implementations such as bubble sort.\n",
    "\n",
    "There are more powerful algorithms, including merge sort and quicksort, but these implementations are recursive and usually fail to beat insertion sort when working on small lists. Some quicksort implementations even use insertion sort internally if the list is small enough to provide a faster overall implementation.That said, insertion sort is not practical for large arrays, opening the door to algorithms that can scale in more efficient ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> 3. Merge Sort  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This divide and conquer algorithm splits a list in half, and keeps splitting the list by 2 until it only has singular elements. Adjacent elements become sorted pairs, then sorted pairs are merged and sorted with other pairs as well. This process continues until we get a sorted list with all the elements of the unsorted input list.\n",
    "\n",
    "We recursively split the list in half until we have lists with size one. We then merge each half that was split, sorting them in the process. Sorting is done by comparing the smallest elements of each half. The first element of each list are the first to be compared. If the first half begins with a smaller value, then we add that to the sorted list. We then compare the second smallest value of the first half with the first smallest value of the second half.\n",
    "\n",
    "Every time we select the smaller value at the beginning of a half, we move the index of which item needs to be compared by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the merge sort algorithm needs two different pieces:\n",
    "\n",
    "- A function that recursively splits the input in half\n",
    "- A function that merges both halves, producing a sorted array\n",
    "\n",
    "Here's an implementation of merge sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(left, right):\n",
    "    # If the first array is empty, then nothing needs\n",
    "    # to be merged, and you can return the second array as the result\n",
    "    if len(left) == 0:\n",
    "        return right\n",
    "\n",
    "    # If the second array is empty, then nothing needs\n",
    "    # to be merged, and you can return the first array as the result\n",
    "    if len(right) == 0:\n",
    "        return left\n",
    "\n",
    "    result = []\n",
    "    index_left = index_right = 0\n",
    "\n",
    "    # Now go through both arrays until all the elements\n",
    "    # make it into the resultant array\n",
    "    while len(result) < len(left) + len(right):\n",
    "        # The elements need to be sorted to add them to the\n",
    "        # resultant array, so you need to decide whether to get\n",
    "        # the next element from the first or the second array\n",
    "        if left[index_left] <= right[index_right]:\n",
    "            result.append(left[index_left])\n",
    "            index_left += 1\n",
    "        else:\n",
    "            result.append(right[index_right])\n",
    "            index_right += 1\n",
    "\n",
    "        # If you reach the end of either array, then you can\n",
    "        # add the remaining elements from the other array to\n",
    "        # the result and break the loop\n",
    "        if index_right == len(right):\n",
    "            result += left[index_left:]\n",
    "            break\n",
    "\n",
    "        if index_left == len(left):\n",
    "            result += right[index_right:]\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "def merge_sort(array):\n",
    "    # If the input array contains fewer than two elements,\n",
    "    # then return it as the result of the function\n",
    "    if len(array) < 2:\n",
    "        return array\n",
    "\n",
    "    midpoint = len(array) // 2\n",
    "\n",
    "    # Sort the array by recursively splitting the input\n",
    "    # into two equal halves, sorting each half and merging them\n",
    "    # together into the final result\n",
    "    return merge(\n",
    "        left=merge_sort(array[:midpoint]),\n",
    "        right=merge_sort(array[midpoint:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Sort's Big O Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the complexity of merge sort, you can look at its two steps separately:\n",
    "\n",
    "merge() has a linear runtime. It receives two arrays whose combined length is at most n (the length of the original input array), and it combines both arrays by looking at each element at most once. This leads to a runtime complexity of O(n).\n",
    "\n",
    "The second step splits the input array recursively and calls merge() for each half. Since the array is halved until a single element remains, the total number of halving operations performed by this function is $log_{2}$n. Since merge() is called for each half, we get a total runtime of O(n $log_{2}$n).\n",
    "\n",
    "Interestingly, O(n $log_{2}$n) is the best possible worst-case runtime that can be achieved by a sorting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Merge Sort Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: merge_sort. Minimum execution time: 0.9003775000019232\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array you just created\n",
    "    run_sorting_algorithm(algorithm=\"merge_sort\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Merge Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to its runtime complexity of O(n $log_{2}$n), merge sort is a very efficient algorithm that scales well as the size of the input array grows. It’s also straightforward to parallelize because it breaks the input array into chunks that can be distributed and processed in parallel if necessary.That said, for small lists, the time cost of the recursion allows algorithms such as bubble sort and insertion sort to be faster.\n",
    "\n",
    "Another drawback of merge sort is that it creates copies of the array when calling itself recursively. It also creates a new list inside merge() to sort and return both input halves. This makes merge sort use much more memory than bubble sort and insertion sort, which are both able to sort the list in place.Due to this limitation, you may not want to use merge sort to sort large lists in memory-constrained hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> 4. Quick Sort  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This divide and conquer algorithm is the most often used sorting algorithm. When configured correctly, it's extremely efficient and does not require the extra space Merge Sort uses. We partition the list around a pivot element, sorting values around the pivot.\n",
    "\n",
    "Quick Sort begins by partitioning the list - picking one value of the list that will be in its sorted place. This value is called a pivot. All elements smaller than the pivot are moved to its left. All larger elements are moved to its right. Knowing that the pivot is in it's rightful place, we recursively sort the values around the pivot until the entire list is sorted.\n",
    "\n",
    "Here's an implementation of quick sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def quicksort(array):\n",
    "    # If the input array contains fewer than two elements,\n",
    "    # then return it as the result of the function\n",
    "    if len(array) < 2:\n",
    "        return array\n",
    "\n",
    "    low, same, high = [], [], []\n",
    "\n",
    "    # Select your `pivot` element randomly\n",
    "    pivot = array[randint(0, len(array) - 1)]\n",
    "\n",
    "    for item in array:\n",
    "        # Elements that are smaller than the `pivot` go to\n",
    "        # the `low` list. Elements that are larger than\n",
    "        # `pivot` go to the `high` list. Elements that are\n",
    "        # equal to `pivot` go to the `same` list.\n",
    "        if item < pivot:\n",
    "            low.append(item)\n",
    "        elif item == pivot:\n",
    "            same.append(item)\n",
    "        elif item > pivot:\n",
    "            high.append(item)\n",
    "\n",
    "    # The final result combines the sorted `low` list\n",
    "    # with the `same` list and the sorted `high` list\n",
    "    return quicksort(low) + same + quicksort(high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Sort's Big O Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With quicksort, the input list is partitioned in linear time, O(n), and this process repeats recursively an average of log2n times. This leads to a final complexity of O(n $log_2n$).\n",
    "\n",
    "That said, remember the discussion about how the selection of the pivot affects the runtime of the algorithm. The O(n) best-case scenario happens when the selected pivot is close to the median of the array, and an O($n^2$) scenario happens when the pivot is the smallest or largest value of the array.\n",
    "\n",
    "Theoretically, if the algorithm focuses first on finding the median value and then uses it as the pivot element, then the worst-case complexity will come down to O(n $log_2n$). The median of an array can be found in linear time, and using it as the pivot guarantees the quicksort portion of the code will perform in O(n $log_2n$).\n",
    "\n",
    "By using the median value as the pivot, you end up with a final runtime of O(n) + O(n log2n). You can simplify this down to O(n $log_2n$) because the logarithmic portion grows much faster than the linear portion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Quick Sort Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: quicksort. Minimum execution time: 0.16067899999325164\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array you just created\n",
    "    run_sorting_algorithm(algorithm=\"quicksort\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Quick Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True to its name, quicksort is very fast. Although its worst-case scenario is theoretically O($n^2$), in practice, a good implementation of quicksort beats most other sorting implementations. Also, just like merge sort, quicksort is straightforward to parallelize.\n",
    "\n",
    "One of quicksort’s main disadvantages is the lack of a guarantee that it will achieve the average runtime complexity. Although worst-case scenarios are rare, certain applications can’t afford to risk poor performance, so they opt for algorithms that stay within O(n $log_2n$) regardless of the input.\n",
    "\n",
    "Just like merge sort, quicksort also trades off memory space for speed. This may become a limitation for sorting larger lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> 5. Timsort  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Timsort algorithm is considered a hybrid sorting algorithm because it employs a best-of-both-worlds combination of insertion sort and merge sort. Timsort is near and dear to the Python community because it was created by Tim Peters in 2002 to be used as the standard sorting algorithm of the Python language.\n",
    "\n",
    "The main characteristic of Timsort is that it takes advantage of already-sorted elements that exist in most real-world datasets. These are called natural runs. The algorithm then iterates over the list, collecting the elements into runs and merging them into a single sorted list.\n",
    "\n",
    "Here's an implementation of Timsort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(array, left=0, right=None):\n",
    "    if right is None:\n",
    "        right = len(array) - 1\n",
    "\n",
    "    # Loop from the element indicated by\n",
    "    # `left` until the element indicated by `right`\n",
    "    for i in range(left + 1, right + 1):\n",
    "        # This is the element we want to position in its\n",
    "        # correct place\n",
    "        key_item = array[i]\n",
    "\n",
    "        # Initialize the variable that will be used to\n",
    "        # find the correct position of the element referenced\n",
    "        # by `key_item`\n",
    "        j = i - 1\n",
    "\n",
    "        # Run through the list of items (the left\n",
    "        # portion of the array) and find the correct position\n",
    "        # of the element referenced by `key_item`. Do this only\n",
    "        # if the `key_item` is smaller than its adjacent values.\n",
    "        while j >= left and array[j] > key_item:\n",
    "            # Shift the value one position to the left\n",
    "            # and reposition `j` to point to the next element\n",
    "            # (from right to left)\n",
    "            array[j + 1] = array[j]\n",
    "            j -= 1\n",
    "\n",
    "        # When you finish shifting the elements, position\n",
    "        # the `key_item` in its correct location\n",
    "        array[j + 1] = key_item\n",
    "\n",
    "    return array\n",
    "\n",
    "def timsort(array):\n",
    "    min_run = 32\n",
    "    n = len(array)\n",
    "\n",
    "    # Start by slicing and sorting small portions of the\n",
    "    # input array. The size of these slices is defined by\n",
    "    # your `min_run` size.\n",
    "    for i in range(0, n, min_run):\n",
    "        insertion_sort(array, i, min((i + min_run - 1), n - 1))\n",
    "\n",
    "    # Now you can start merging the sorted slices.\n",
    "    # Start from `min_run`, doubling the size on\n",
    "    # each iteration until you surpass the length of\n",
    "    # the array.\n",
    "    size = min_run\n",
    "    while size < n:\n",
    "        # Determine the arrays that will\n",
    "        # be merged together\n",
    "        for start in range(0, n, size * 2):\n",
    "            # Compute the `midpoint` (where the first array ends\n",
    "            # and the second starts) and the `endpoint` (where\n",
    "            # the second array ends)\n",
    "            midpoint = start + size - 1\n",
    "            end = min((start + size * 2 - 1), (n-1))\n",
    "\n",
    "            # Merge the two subarrays.\n",
    "            # The `left` array should go from `start` to\n",
    "            # `midpoint + 1`, while the `right` array should\n",
    "            # go from `midpoint + 1` to `end + 1`.\n",
    "            merged_array = merge(\n",
    "                left=array[start:midpoint + 1],\n",
    "                right=array[midpoint + 1:end + 1])\n",
    "\n",
    "            # Finally, put the merged array back into\n",
    "            # your array\n",
    "            array[start:start + len(merged_array)] = merged_array\n",
    "\n",
    "        # Each iteration should double the size of your arrays\n",
    "        size *= 2\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timsort's Big O Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the complexity of Timsort is O(n $log_2n$), just like merge sort and quicksort. The logarithmic part comes from doubling the size of the run to perform each linear merge operation.\n",
    "\n",
    "However, Timsort performs exceptionally well on already-sorted or close-to-sorted lists, leading to a best-case scenario of O(n). In this case, Timsort clearly beats merge sort and matches the best-case scenario for quicksort. But the worst case for Timsort is also O(n $log_2n$), which surpasses quicksort’s O($n^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Timsort Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: timsort. Minimum execution time: 0.7365843999999697\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate an array of `ARRAY_LENGTH` items consisting\n",
    "    # of random integer values between 0 and 999\n",
    "    array = [randint(0, 1000) for i in range(ARRAY_LENGTH)]\n",
    "\n",
    "    # Call the function using the name of the sorting algorithm\n",
    "    # and the array you just created\n",
    "    run_sorting_algorithm(algorithm=\"timsort\", array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses of Timsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main disadvantage of Timsort is its complexity. Despite implementing a very simplified version of the original algorithm, it still requires much more code because it relies on both insertion_sort() and merge().\n",
    "\n",
    "One of Timsort’s advantages is its ability to predictably perform in O(n $log_2n$) regardless of the structure of the input array. Contrast that with quicksort, which can degrade down to O($n^2$). Timsort is also very fast for small arrays because the algorithm turns into a single insertion sort.\n",
    "\n",
    "For real-world usage, in which it’s common to sort arrays that already have some preexisting order, Timsort is a great option. Its adaptability makes it an excellent choice for sorting arrays of any length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
